{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "YjQELk9tpIUT"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install --quiet numpy pandas matplotlib scikit-learn torch torchvision torchaudio pytorch-lightning wandb rich ipywidgets tabulate tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "U9ixi9gLM9J1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    balanced_accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import (\n",
        "    ModelCheckpoint,\n",
        "    EarlyStopping,\n",
        "    LearningRateMonitor,\n",
        "    RichProgressBar\n",
        ")\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "from tqdm import tqdm\n",
        "from huggingface_hub import snapshot_download, hf_hub_download\n",
        "import zipfile\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "RJ-0SzIdNDJV"
      },
      "outputs": [],
      "source": [
        "# download the compute_cost.py file\n",
        "pyfile_path = hf_hub_download(\n",
        "    repo_id=\"fschmid56/mlpc2025_dataset\",\n",
        "    filename=\"compute_cost.py\",\n",
        "    repo_type=\"dataset\"\n",
        ")\n",
        "\n",
        "# move to current working directory (/content)\n",
        "shutil.copy(pyfile_path, os.getcwd() + \"/compute_cost.py\")\n",
        "\n",
        "# import required functions\n",
        "from compute_cost import CLASSES as TARGET_CLASSES\n",
        "from compute_cost import (\n",
        "    aggregate_targets,\n",
        "    get_ground_truth_df,\n",
        "    get_segment_prediction_df,\n",
        "    check_dataframe,\n",
        "    total_cost\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-s_PRkPNIxE",
        "outputId": "88d056f3-066f-4212-fcaf-369c8a025e14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ ZIP downloaded: /root/.cache/huggingface/hub/datasets--fschmid56--mlpc2025_dataset/snapshots/5ecbfd8531c18fbb4fa60b79eacdf585b1f1aac4/mlpc2025_dataset.zip\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Download the ZIP file from HF Hub\n",
        "zip_path = hf_hub_download(\n",
        "    repo_id=\"fschmid56/mlpc2025_dataset\",   # your dataset repo\n",
        "    filename=\"mlpc2025_dataset.zip\",        # your uploaded ZIP file\n",
        "    repo_type=\"dataset\"                     # specify that it's a dataset repo\n",
        ")\n",
        "\n",
        "print(f\"✅ ZIP downloaded: {zip_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZoCPtxyNNtd",
        "outputId": "eb4a2755-cb73-4202-bee6-9a892f97298e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset already extracted at /content/mlpc2025_dataset\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Extract the ZIP\n",
        "extract_path = \"/content/mlpc2025_dataset\"\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Check if already extracted\n",
        "if not os.path.exists(os.path.join(extract_path, \"data\")):  # assuming 'data/' is inside the zip\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "    print(f\"✅ Dataset extracted to {extract_path}\")\n",
        "else:\n",
        "    print(f\"✅ Dataset already extracted at {extract_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACIiozUKOq4K",
        "outputId": "32826129-576c-4c62-98db-319c5534a010"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ DATASET_PATH set to /content/mlpc2025_dataset/data\n",
            "Files in DATASET_PATH: ['metadata.csv', '.cache', 'audio_features', 'customer_test_data', 'labels', 'annotations.csv', 'audio']\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Set your DATASET_PATH\n",
        "DATASET_PATH = os.path.join(extract_path, \"data\")  # because you zipped the 'data' folder\n",
        "print(f\"✅ DATASET_PATH set to {DATASET_PATH}\")\n",
        "\n",
        "# Quick check\n",
        "print(\"Files in DATASET_PATH:\", os.listdir(DATASET_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "8TTf3yIIPOak"
      },
      "outputs": [],
      "source": [
        "METADATA_CSV = os.path.join(DATASET_PATH, 'metadata.csv')\n",
        "ANNOTATIONS_CSV = os.path.join(DATASET_PATH, 'annotations.csv')\n",
        "AUDIO_DIR = os.path.join(DATASET_PATH, 'audio')\n",
        "AUDIO_FEATURES_DIR = os.path.join(DATASET_PATH, 'audio_features')\n",
        "LABELS_DIR = os.path.join(DATASET_PATH, 'labels')\n",
        "\n",
        "METADATA = pd.read_csv(METADATA_CSV)\n",
        "DEV_SET_FILES = METADATA['filename']\n",
        "\n",
        "CUSTOMER_DATASET_PATH = os.path.join(DATASET_PATH, 'customer_test_data')\n",
        "CUSTOMER_AUDIO_DIR = os.path.join(CUSTOMER_DATASET_PATH, 'audio')\n",
        "CUSTOMER_AUDIO_FEATURES_DIR = os.path.join(CUSTOMER_DATASET_PATH, 'audio_features')\n",
        "CUSTOMER_METADATA_CSV = os.path.join(CUSTOMER_DATASET_PATH, 'metadata.csv')\n",
        "CUSTOMER_METADATA = pd.read_csv(CUSTOMER_METADATA_CSV)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "VHIOi5dUPYh0"
      },
      "outputs": [],
      "source": [
        "def read_files(file_names, classes, features_dir=AUDIO_FEATURES_DIR, labels_dir=LABELS_DIR):\n",
        "    \"\"\"\n",
        "    Loads features and binary labels for a list of files.\n",
        "\n",
        "    Returns:\n",
        "        X: list of np.ndarrays, each of shape (num_frames, num_features)\n",
        "        Y: dict of lists of np.ndarrays, each of shape (num_frames,)\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    Y = {c: [] for c in classes} if labels_dir is not None else None\n",
        "\n",
        "    for fname in file_names:\n",
        "        base = os.path.splitext(fname)[0]\n",
        "\n",
        "        # Load features\n",
        "        feat_path = os.path.join(features_dir, base + '.npz')\n",
        "        features = np.load(feat_path)['embeddings']  # shape: (T, D)\n",
        "        X.append(features)\n",
        "\n",
        "        if labels_dir is not None:\n",
        "            # Load labels\n",
        "            label_path = os.path.join(labels_dir, base + '_labels.npz')\n",
        "            labels = np.load(label_path)\n",
        "\n",
        "            for c in classes:\n",
        "                label_array = labels[c]  # shape: (T, num_annotators)\n",
        "                binary_labels = (np.max(label_array, axis=1) > 0).astype(int)\n",
        "                Y[c].append(binary_labels)  # shape: (T,)\n",
        "\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dV8JUnMbPeRD",
        "outputId": "0627839d-79eb-436d-aaf5-6b42e6f8e480"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 4938, Val: 1646, Test: 1646\n"
          ]
        }
      ],
      "source": [
        "# Get filenames for split based on filenames\n",
        "all_files = DEV_SET_FILES.unique()\n",
        "\n",
        "# First split: 60% train, 40% temp (val + test)\n",
        "train_files, temp_files = train_test_split(\n",
        "    all_files, test_size=0.4, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "# Second split: 50% val, 50% test from the remaining 40%\n",
        "val_files, test_files = train_test_split(\n",
        "    temp_files, test_size=0.5, random_state=42, shuffle=True\n",
        ")\n",
        "\n",
        "\n",
        "print(f\"Train: {len(train_files)}, Val: {len(val_files)}, Test: {len(test_files)}\")\n",
        "\n",
        "# Load features and labels\n",
        "X_train, Y_train = read_files(train_files, TARGET_CLASSES)\n",
        "X_val, Y_val = read_files(val_files, TARGET_CLASSES)\n",
        "X_test, Y_test = read_files(test_files, TARGET_CLASSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "Sksv9WZjvzs4"
      },
      "outputs": [],
      "source": [
        "class_list = ['Speech','Dog Bark','Rooster Crow','Shout','Lawn Mower','Chainsaw','Jackhammer','Power Drill','Horn Honk','Siren']\n",
        "\n",
        "FP = [1,1,2,3,3,3,3,3,3,3]\n",
        "FN = [5,5,10,10,20,15,20,15,20,15] # increased lawn mover and jackhammer cost since their loss hasnot been decreasing\n",
        "pos_weights = np.array(FN)/np.array(FP )\n",
        "\n",
        "#pos_weights=[1,1,1,2,4,3,4,3,3,3]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "uValCQpmQ-Sn"
      },
      "outputs": [],
      "source": [
        "def evaluate_classifiers(\n",
        "    classes: list[str],\n",
        "    Y_val: dict[str, list[np.ndarray]],\n",
        "    X_val: list[np.ndarray] = None,\n",
        "    inference_funcs: dict[str, callable] = None,\n",
        "    Y_pred: dict[str, list[np.ndarray]] = None\n",
        ") -> tuple[dict[str, list[np.ndarray]], dict[str, dict]]:\n",
        "    \"\"\"\n",
        "    Evaluates per-frame binary classifiers and computes metrics per class.\n",
        "    Uses either computed predictions or given inference functions.\n",
        "\n",
        "    Args:\n",
        "        classes: List of class names to evaluate.\n",
        "        Y_val: Dict mapping class names to lists of ground-truth (T,) binary arrays.\n",
        "        X_val: List of input feature arrays, one per validation file. Required if Y_pred not given.\n",
        "        inference_funcs: Dict mapping class names to binary inference functions.\n",
        "        Y_pred: Dict with precomputed predictions (same format as Y_val).\n",
        "\n",
        "    Returns:\n",
        "        metrics: Dict[class → {'balanced_accuracy', 'precision', 'recall', 'f1'}].\n",
        "    \"\"\"\n",
        "\n",
        "    if Y_pred is None:\n",
        "        assert inference_funcs is not None and X_val is not None, \"If 'Y_pred' is not given, 'inference_funcs' \\\n",
        "                                                                    and 'X_val' must be given.\"\n",
        "\n",
        "    Y_val_preds = {}\n",
        "    metrics     = {}\n",
        "\n",
        "    for cls in classes:\n",
        "        # use predictions if given, else infer\n",
        "        if Y_pred and cls in Y_pred:\n",
        "            preds_per_file = Y_pred[cls]\n",
        "        else:\n",
        "            infer = inference_funcs[cls]\n",
        "            preds_per_file = [infer(x_file) for x_file in X_val]\n",
        "        Y_val_preds[cls] = preds_per_file\n",
        "\n",
        "        # flatten to compute metrics\n",
        "        y_true = np.concatenate(Y_val[cls])\n",
        "        y_pred = np.concatenate(preds_per_file)\n",
        "\n",
        "        metrics[cls] = {\n",
        "            \"balanced_accuracy\": balanced_accuracy_score(y_true, y_pred),\n",
        "            \"precision\":         precision_score(y_true, y_pred, zero_division=0),\n",
        "            \"recall\":            recall_score(y_true, y_pred, zero_division=0),\n",
        "            \"f1\":                f1_score(y_true, y_pred, zero_division=0),\n",
        "        }\n",
        "\n",
        "    return metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "gdi2K-gLQ_1s"
      },
      "outputs": [],
      "source": [
        "def evaluate_cost(\n",
        "    val_files: list[str],\n",
        "    dataset_path: str,\n",
        "    classes: list[str],\n",
        "    X_val: list[np.ndarray] = None,\n",
        "    inference_funcs: dict[str, callable] = None,\n",
        "    Y_pred: dict[str, list[np.ndarray]] = None\n",
        "):\n",
        "    \"\"\"\n",
        "    Computes segment-level cost based on predictions and ground truth.\n",
        "    Uses either computed predictions or given inference functions.\n",
        "\n",
        "    Args:\n",
        "        val_files: List of filenames corresponding to X_val.\n",
        "        dataset_path: Path to dataset root (used for loading ground truth).\n",
        "        classes: List of class names to evaluate.\n",
        "        X_val: List of input feature arrays, one per validation file. Required if Y_pred not given.\n",
        "        inference_funcs: Dict mapping class names to binary inference functions.\n",
        "        Y_pred: Dict with precomputed predictions (class → list of (T,) arrays).\n",
        "\n",
        "    Returns:\n",
        "        total: Total cost across all validation files.\n",
        "        breakdown: Dict[class → segment-level cost].\n",
        "    \"\"\"\n",
        "\n",
        "    if Y_pred is None:\n",
        "        assert inference_funcs is not None and X_val is not None, \"If 'Y_pred' is not given, 'inference_funcs' \\\n",
        "                                                                    and 'X_val' must be given.\"\n",
        "\n",
        "    # 0) frame-wise predictions (per class)\n",
        "    if Y_pred is None:\n",
        "        Y_pred = {\n",
        "            cls: [infer(x_file) for x_file in X_val]\n",
        "            for cls, infer in inference_funcs.items()\n",
        "        }\n",
        "\n",
        "    # 1) restructure to filename -> class -> (T,) array\n",
        "    preds_by_file = {}\n",
        "    for i, fname in enumerate(val_files):\n",
        "        preds_by_file[fname] = {\n",
        "            cls: Y_pred[cls][i] for cls in classes\n",
        "        }\n",
        "\n",
        "    # 2) segment-level aggregation using compute_cost\n",
        "    pred_df = get_segment_prediction_df(\n",
        "        predictions=preds_by_file,\n",
        "        class_names=classes\n",
        "    )\n",
        "\n",
        "    # 3) load & aggregate ground truth using compute_cost\n",
        "    gt_df = get_ground_truth_df(val_files, dataset_path)\n",
        "\n",
        "    # 4) sanity checks from compute_cost\n",
        "    check_dataframe(pred_df, dataset_path)\n",
        "    check_dataframe(gt_df, dataset_path)\n",
        "\n",
        "    # 5) compute cost\n",
        "    total, breakdown = total_cost(pred_df, gt_df)\n",
        "\n",
        "    return total, breakdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "8AOywRAoRF0h"
      },
      "outputs": [],
      "source": [
        "class SequenceDataset(Dataset):\n",
        "    def __init__(self, X, Y, classes, filenames, apply_log_mel=False, eps=1e-6,\n",
        "                 mean=None, std=None):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "        self.classes = classes\n",
        "        self.filenames = filenames\n",
        "        self.apply_log_mel = apply_log_mel\n",
        "        self.eps = eps\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_tensor = torch.tensor(self.X[idx], dtype=torch.float32)\n",
        "        if self.apply_log_mel:\n",
        "            x_tensor = torch.log10(x_tensor + self.eps)\n",
        "\n",
        "\n",
        "\n",
        "        if self.Y is not None:\n",
        "            y_tensor = torch.stack([\n",
        "                torch.tensor(self.Y[c][idx], dtype=torch.long) for c in self.classes\n",
        "            ], dim=1)\n",
        "            return x_tensor, y_tensor, self.filenames[idx]\n",
        "        else:\n",
        "            return x_tensor, self.filenames[idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# collate_fn used to create batches from the individual dataset items\n",
        "def collate_fn(batch):\n",
        "    if len(batch[0]) == 3:\n",
        "        Xs, Ys, filenames = zip(*batch)\n",
        "        lengths = torch.tensor([x.size(0) for x in Xs], dtype=torch.long)\n",
        "        X_padded = pad_sequence(Xs, batch_first=True)\n",
        "        Y_padded = pad_sequence(Ys, batch_first=True)\n",
        "        return X_padded, Y_padded, lengths, list(filenames)\n",
        "    elif len(batch[0]) == 2:\n",
        "        Xs, filenames = zip(*batch)\n",
        "        lengths = torch.tensor([x.size(0) for x in Xs], dtype=torch.long)\n",
        "        X_padded = pad_sequence(Xs, batch_first=True)\n",
        "        return X_padded, lengths, list(filenames)\n",
        "    else:\n",
        "        raise ValueError(\"Unexpected batch format: expected 2 or 3 elements per item.\")"
      ],
      "metadata": {
        "id": "UmbF1wnTPfX-"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sdrcz8qOOuBQ"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def compute_dataset_mean_std(X, eps=1e-6):\n",
        "    \"\"\"\n",
        "    Compute global mean and std across all time steps and samples.\n",
        "\n",
        "    Args:\n",
        "        X: list of np.ndarray or torch.Tensor, each of shape (T_i, D)\n",
        "\n",
        "    Returns:\n",
        "        mean: torch.Tensor of shape (D,)\n",
        "        std: torch.Tensor of shape (D,)\n",
        "    \"\"\"\n",
        "    if isinstance(X[0], np.ndarray):\n",
        "        X = [torch.tensor(x, dtype=torch.float32) for x in X]\n",
        "\n",
        "    # Concatenate along time dimension\n",
        "    all_data = torch.cat(X, dim=0)  # shape: (sum(T_i), D)\n",
        "\n",
        "    mean = all_data.mean(dim=0)     # shape: (D,)\n",
        "    std = all_data.std(dim=0) + eps  # shape: (D,)\n",
        "    return mean, std\n"
      ],
      "metadata": {
        "id": "aevyyajgNAUV"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mu,std =compute_dataset_mean_std(X_train)"
      ],
      "metadata": {
        "id": "VaL_SMbQNCqn"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "2JadmkfaRPrS"
      },
      "outputs": [],
      "source": [
        "ds = SequenceDataset(X_train, Y_train, TARGET_CLASSES, train_files, apply_log_mel=True, eps=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "XpevVfgvRQSJ"
      },
      "outputs": [],
      "source": [
        "# collate_fn used to create batches from the individual dataset items\n",
        "def collate_fn(batch):\n",
        "    if len(batch[0]) == 3:\n",
        "        Xs, Ys, filenames = zip(*batch)\n",
        "        lengths = torch.tensor([x.size(0) for x in Xs], dtype=torch.long)\n",
        "        X_padded = pad_sequence(Xs, batch_first=True)\n",
        "        Y_padded = pad_sequence(Ys, batch_first=True)\n",
        "        return X_padded, Y_padded, lengths, list(filenames)\n",
        "    elif len(batch[0]) == 2:\n",
        "        Xs, filenames = zip(*batch)\n",
        "        lengths = torch.tensor([x.size(0) for x in Xs], dtype=torch.long)\n",
        "        X_padded = pad_sequence(Xs, batch_first=True)\n",
        "        return X_padded, lengths, list(filenames)\n",
        "    else:\n",
        "        raise ValueError(\"Unexpected batch format: expected 2 or 3 elements per item.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "tYn6WJ7eRU_2"
      },
      "outputs": [],
      "source": [
        "batch = [ds[i] for i in range(32)]\n",
        "X_pad, Y_pad, lengths, filenames = collate_fn(batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "U8XndzUTRyoq"
      },
      "outputs": [],
      "source": [
        "# DataModule is used by pytorch lightning\n",
        "class SEDDataModule(pl.LightningDataModule):\n",
        "    def __init__(self,\n",
        "                 X_train, Y_train, train_files,\n",
        "                 X_val,   Y_val,   val_files,\n",
        "                 X_test,  Y_test,  test_files,\n",
        "                 classes,\n",
        "                 batch_size=32,\n",
        "                 num_workers=4):\n",
        "        super().__init__()\n",
        "        self.X_train, self.Y_train, self.train_files = X_train, Y_train, train_files\n",
        "        self.X_val,   self.Y_val,   self.val_files   = X_val,   Y_val,   val_files\n",
        "        self.X_test,  self.Y_test,  self.test_files  = X_test,  Y_test,  test_files\n",
        "        self.classes     = classes\n",
        "        self.batch_size  = batch_size\n",
        "        self.num_workers = num_workers\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        self.train_ds = SequenceDataset(self.X_train, self.Y_train, self.classes, self.train_files, apply_log_mel=False)\n",
        "        self.val_ds   = SequenceDataset(self.X_val,   self.Y_val,   self.classes, self.val_files, apply_log_mel=False)\n",
        "        self.test_ds  = SequenceDataset(self.X_test,  self.Y_test,  self.classes, self.test_files, apply_log_mel=False)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_ds,\n",
        "                          batch_size=self.batch_size,\n",
        "                          shuffle=True,\n",
        "                          collate_fn=collate_fn,\n",
        "                          num_workers=self.num_workers)\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_ds,\n",
        "                          batch_size=self.batch_size,\n",
        "                          shuffle=False,\n",
        "                          collate_fn=collate_fn,\n",
        "                          num_workers=self.num_workers)\n",
        "\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_ds,\n",
        "                          batch_size=self.batch_size,\n",
        "                          shuffle=False,\n",
        "                          collate_fn=collate_fn,\n",
        "                          num_workers=self.num_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyNmAIn4R3XD",
        "outputId": "a91d597a-045e-48cb-b7c0-63049782b00b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataModule batch -> X: torch.Size([32, 249, 768]) \n",
            "Y: torch.Size([32, 249, 10]) \n",
            "lengths: tensor([167, 135, 209, 161, 226, 185, 143, 249, 149, 173, 210, 226, 220, 210,\n",
            "        242, 152, 164, 230, 138, 173, 239, 188, 140, 193, 139, 184, 201, 183,\n",
            "        207, 155, 205, 234]) \n",
            "filenames: ['250924.mp3', '28127.mp3', '646030.mp3'] ...\n"
          ]
        }
      ],
      "source": [
        "dm = SEDDataModule(\n",
        "    X_train=X_train, Y_train=Y_train, train_files=train_files,\n",
        "    X_val=X_val,     Y_val=Y_val,     val_files=val_files,\n",
        "    X_test=X_test,   Y_test=Y_test,   test_files=test_files,\n",
        "    classes=TARGET_CLASSES,\n",
        "    batch_size=32,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "dm.setup()\n",
        "loader = dm.train_dataloader()\n",
        "X_batch, Y_batch, len_batch, filenames = next(iter(loader))\n",
        "print(\"DataModule batch -> X:\", X_batch.shape,\n",
        "      \"\\nY:\", Y_batch.shape,\n",
        "      \"\\nlengths:\", len_batch,\n",
        "      \"\\nfilenames:\", filenames[:3], \"...\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class LearnablePositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.max_len = max_len\n",
        "\n",
        "        # Create learnable positional embeddings\n",
        "        self.pe = nn.Parameter(torch.zeros(max_len, d_model))  # Trainable parameter\n",
        "        nn.init.normal_(self.pe, mean=0.0, std=0.02)  # Small random initialization\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (batch_size, seq_len, d_model)\n",
        "        seq_len = x.size(1)\n",
        "\n",
        "        # Add positional encoding to each sequence element\n",
        "        return x + self.pe[:seq_len, :]  # (B, T, d_model) + (T, d_model)"
      ],
      "metadata": {
        "id": "qBTJFe0UUClX"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "ilnvCybYR5hE"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, num_classes=10, em_dim=768, reduced_dim=256, n_heads=4, n_layers=4, max_len=5000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.pos_encoder = LearnablePositionalEncoding(d_model=1024, max_len=max_len)\n",
        "\n",
        "        # Convolutional feature extractor on full em_dim\n",
        "        # self.conv = nn.Sequential(\n",
        "        #     nn.Conv1d(em_dim, em_dim, kernel_size=7, padding=\"same\", groups=em_dim),\n",
        "        #     nn.BatchNorm1d(em_dim),\n",
        "        #     nn.ReLU(),\n",
        "\n",
        "        #     nn.Conv1d(em_dim, em_dim, kernel_size=5, padding=\"same\", groups=em_dim),\n",
        "        #     nn.BatchNorm1d(em_dim),\n",
        "        #     nn.ReLU(),\n",
        "\n",
        "        #     nn.Conv1d(em_dim, em_dim, kernel_size=3, padding=\"same\", groups=em_dim),\n",
        "        #     nn.BatchNorm1d(em_dim),\n",
        "        #     nn.ReLU(),\n",
        "        # )\n",
        "\n",
        "        self.proj = nn.Sequential(\n",
        "                nn.Linear(em_dim, 1024),\n",
        "                nn.GELU(),\n",
        "                nn.Linear(1024, 1024)\n",
        "            )\n",
        "\n",
        "        # Transformer encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=1024,\n",
        "            nhead=n_heads,\n",
        "            dropout=0.2,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layers)\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(1024, reduced_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(reduced_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, lengths=None):\n",
        "        # x: (B, T, em_dim)\n",
        "        # x = x.transpose(1, 2)      # (B, em_dim, T)\n",
        "        # x = self.conv(x)           # (B, em_dim, T)\n",
        "        # x = x.transpose(1, 2)      # (B, T, em_dim)\n",
        "\n",
        "        x = self.proj(x)        # (B, T, reduced_dim)\n",
        "        x = self.pos_encoder(x)    # (B, T, reduced_dim)\n",
        "        x = self.transformer(x)    # (B, T, reduced_dim)\n",
        "        return self.classifier(x)  # (B, T, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "inzZaOEpTLad"
      },
      "outputs": [],
      "source": [
        "class SEDLightningModule(pl.LightningModule):\n",
        "    def __init__(self, classes, lr=1e-4, threshold=0.5, dropout=0.3, pos_weight=None):\n",
        "        super().__init__()\n",
        "        # Core model\n",
        "        self.model = Transformer()\n",
        "\n",
        "        self.classes = classes\n",
        "        self.lr = lr\n",
        "        self.threshold = threshold\n",
        "\n",
        "        # Store pos_weight as a buffer if it's a tensor\n",
        "        if pos_weight is not None and isinstance(pos_weight, torch.Tensor):\n",
        "            self.register_buffer(\"pos_weight_tensor\", pos_weight)\n",
        "        else:\n",
        "            self.pos_weight_tensor = pos_weight\n",
        "\n",
        "        # Initialize criterion without pos_weight (we'll handle it in training_step)\n",
        "        self.criterion = nn.BCEWithLogitsLoss(reduction='none')\n",
        "\n",
        "        self._val_preds = {c: [] for c in self.classes}\n",
        "        self._val_targets = {c: [] for c in self.classes}\n",
        "        self._val_filenames = []\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        return self.model(x, lengths)\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        # unpack batch (with or without labels)\n",
        "        if len(batch) == 4:\n",
        "            X, _, lengths, filenames = batch\n",
        "        else:\n",
        "            X, lengths, filenames = batch\n",
        "\n",
        "        # 1) raw logits → probs → binary preds\n",
        "        logits = self.model(X, lengths)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > self.threshold).int()  # (B, T_max, C)\n",
        "\n",
        "        # 2) remove padding\n",
        "        batch_preds = [preds[b, :lengths[b]].cpu()\n",
        "                      for b in range(X.size(0))]\n",
        "\n",
        "        return {\"filenames\": filenames, \"preds\": batch_preds}\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        X, Y, lengths, _ = batch\n",
        "        logits = self(X, lengths)\n",
        "\n",
        "        # Create criterion with current pos_weight\n",
        "        criterion = nn.BCEWithLogitsLoss(\n",
        "            pos_weight=self.pos_weight_tensor.to(logits.device) if self.pos_weight_tensor is not None else None,\n",
        "            reduction='none'\n",
        "        )\n",
        "\n",
        "        loss_raw = criterion(logits, Y.float())\n",
        "        mask = torch.arange(logits.size(1), device=logits.device)[None, :] < lengths[:, None]\n",
        "        mask = mask.unsqueeze(-1).float()\n",
        "        loss = (loss_raw * mask).sum() / mask.sum()\n",
        "\n",
        "        self.log('train/loss', loss, prog_bar=True, on_step=True, on_epoch=True, batch_size=X.size(0))\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return self.process_validation_step(batch, batch_idx)\n",
        "\n",
        "    def on_validation_epoch_end(self):\n",
        "        return self.process_validation_epoch_end()\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return self.process_test_step(batch, batch_idx)\n",
        "\n",
        "    def on_test_epoch_end(self):\n",
        "        return self.process_test_epoch_end()\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        decay = []\n",
        "        no_decay = []\n",
        "\n",
        "        for name, param in self.model.named_parameters():\n",
        "            if param.requires_grad:\n",
        "                if 'bias' in name or 'bn' in name or 'norm' in name:\n",
        "                    no_decay.append(param)\n",
        "                else:\n",
        "                    decay.append(param)\n",
        "\n",
        "        optimizer_grouped = [\n",
        "            {'params': decay, 'weight_decay': 1e-4},\n",
        "            {'params': no_decay, 'weight_decay': 0.0}\n",
        "        ]\n",
        "\n",
        "        return torch.optim.AdamW(optimizer_grouped, lr=self.lr)\n",
        "\n",
        "    @classmethod\n",
        "    def load_from_checkpoint(cls, checkpoint_path, **kwargs):\n",
        "        # First load the checkpoint without strict state_dict checking\n",
        "        model = super().load_from_checkpoint(checkpoint_path, strict=False, **kwargs)\n",
        "\n",
        "        # Manually handle the pos_weight if it exists in the checkpoint\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        if 'criterion.pos_weight' in checkpoint['state_dict']:\n",
        "            pos_weight = checkpoint['state_dict']['criterion.pos_weight']\n",
        "            if isinstance(pos_weight, torch.Tensor):\n",
        "                model.register_buffer(\"pos_weight_tensor\", pos_weight)\n",
        "            else:\n",
        "                model.pos_weight_tensor = pos_weight\n",
        "\n",
        "        return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "aRoFt6GbUylh"
      },
      "outputs": [],
      "source": [
        "def process_training_step(self, batch, batch_idx):\n",
        "    X, Y, lengths, _ = batch      # X: (B, T, D), Y: (B, T, C), lengths: (B,)\n",
        "    logits = self(X,lengths)     # calls self.forward, results in logits of shape (B, T, C)\n",
        "\n",
        "\n",
        "    # raw per-element loss\n",
        "    loss_raw = self.criterion(logits, Y.float())  # (B, T, C)\n",
        "\n",
        "    # build mask to zero out padded frames\n",
        "    mask = torch.arange(logits.size(1), device=logits.device)[None, :] < lengths[:, None]\n",
        "    mask = mask.unsqueeze(-1).float()     # (B, T, 1)\n",
        "\n",
        "    # apply mask and average\n",
        "    loss = (loss_raw * mask).sum() / mask.sum()\n",
        "\n",
        "    self.log('train/loss', loss, prog_bar=True, on_step=True, on_epoch=True, batch_size=X.size(0))\n",
        "    return loss\n",
        "\n",
        "# Bind it to the LightningModule\n",
        "SEDLightningModule.process_training_step = process_training_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "lKIeVISEU26j"
      },
      "outputs": [],
      "source": [
        "def process_validation_step(self, batch, batch_idx):\n",
        "    X, Y, lengths, filenames = batch      # X: (B, T, D), Y: (B, T, C), lengths: (B,)\n",
        "    logits = self(X,lengths)             # calls self.forward, results in logits of shape (B, T, C)\n",
        "\n",
        "    # Determine logging prefix\n",
        "    prefix = \"test\" if self.trainer.testing else \"val\"\n",
        "\n",
        "    # compute masked BCE loss\n",
        "    loss_raw = self.criterion(logits, Y.float())     # (B, T, C)\n",
        "    mask = torch.arange(logits.size(1), device=logits.device)[None, :] < lengths[:, None]\n",
        "    mask = mask.unsqueeze(-1).float()                # (B, T, 1)\n",
        "    loss = (loss_raw * mask).sum() / mask.sum()\n",
        "\n",
        "    self.log(f'{prefix}/loss', loss, prog_bar=True, on_step=False, on_epoch=True, batch_size=X.size(0))\n",
        "\n",
        "    # store frame-wise preds & targets for epoch_end\n",
        "    # frame-wise logits are thresholded here\n",
        "    preds = (torch.sigmoid(logits) > self.threshold).long()     # (B, T, C)\n",
        "    self._val_filenames.extend(filenames)\n",
        "\n",
        "    for i, c in enumerate(self.classes):\n",
        "        for b in range(X.size(0)):\n",
        "            T = lengths[b]\n",
        "            self._val_preds[c].append(preds[b, :T, i])\n",
        "            self._val_targets[c].append(Y[b, :T, i])\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Bind it to the LightningModule\n",
        "SEDLightningModule.process_validation_step = process_validation_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "TNYinNyRU47k"
      },
      "outputs": [],
      "source": [
        "def process_validation_epoch_end(self):\n",
        "    # Determine current mode\n",
        "    prefix = \"test\" if self.trainer.testing else \"val\"\n",
        "\n",
        "    # --- 1) Convert buffered tensors to NumPy arrays ---\n",
        "    preds_numpy = {\n",
        "        cls: [p.cpu().numpy() for p in self._val_preds[cls]]\n",
        "        for cls in self.classes\n",
        "    }\n",
        "    targets_numpy = {\n",
        "        cls: [t.cpu().numpy() for t in self._val_targets[cls]]\n",
        "        for cls in self.classes\n",
        "    }\n",
        "\n",
        "    # --- 2) Frame‐level metrics ---\n",
        "    frame_metrics = evaluate_classifiers(\n",
        "        classes=self.classes,\n",
        "        Y_val=targets_numpy,\n",
        "        Y_pred=preds_numpy\n",
        "    )\n",
        "\n",
        "    for cls, m in frame_metrics.items():\n",
        "        self.log(f'{prefix}/{cls}_bacc',     m['balanced_accuracy'])\n",
        "        self.log(f'{prefix}/{cls}_precision',m['precision'])\n",
        "        self.log(f'{prefix}/{cls}_recall',   m['recall'])\n",
        "        self.log(f'{prefix}/{cls}_f1',       m['f1'])\n",
        "\n",
        "    # --- 3) Segment‐level cost ---\n",
        "    total_cost, cost_breakdown = evaluate_cost(\n",
        "        val_files=self._val_filenames,\n",
        "        dataset_path=DATASET_PATH,\n",
        "        classes=self.classes,\n",
        "        Y_pred=preds_numpy\n",
        "    )\n",
        "    self.log(f'{prefix}/total_cost', total_cost, prog_bar=True)\n",
        "    for cls, cls_cost in cost_breakdown.items():\n",
        "        self.log(f\"{prefix}/cost/{cls}\", cls_cost[\"cost\"], prog_bar=False)\n",
        "\n",
        "    # --- 4) Clear buffers ---\n",
        "    self._val_preds     = {c: [] for c in self.classes}\n",
        "    self._val_targets   = {c: [] for c in self.classes}\n",
        "    self._val_filenames = []\n",
        "\n",
        "\n",
        "SEDLightningModule.process_validation_epoch_end = process_validation_epoch_end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "QM-W57pLU8l2"
      },
      "outputs": [],
      "source": [
        "# After you’ve attached the validation logic, simply reuse it for testing:\n",
        "\n",
        "# Reuse the same step‐logic\n",
        "SEDLightningModule.process_test_step = SEDLightningModule.process_validation_step\n",
        "\n",
        "# Reuse the same epoch‐end logic\n",
        "SEDLightningModule.process_test_epoch_end = SEDLightningModule.process_validation_epoch_end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "AmLE8CzmU_kr"
      },
      "outputs": [],
      "source": [
        "hparams = dict(\n",
        "    input_dim      = X_batch.shape[-1],   # Feature dimension (e.g., 64 for Mel)\n",
        "    num_classes    = Y_batch.shape[-1],   # Number of output classes\n",
        "    dropout        = 0.3,                 # Dropout\n",
        "    lr             = 1e-5,                # Learning rate\n",
        "    pos_weight     = torch.tensor(pos_weights),          # To handle class imbalance\n",
        "    batch_size     = 32,\n",
        "    max_epochs     = 100,\n",
        "    threshold      = 0.5,\n",
        "    patience       = 10                    # For early stopping\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "VUDBShQPVK78"
      },
      "outputs": [],
      "source": [
        "checkpoint_cb = ModelCheckpoint(\n",
        "    monitor    = \"val/total_cost\",   # minimize cost\n",
        "    mode       = \"min\",\n",
        "    save_top_k = 1,                  # save top model on validation data\n",
        "    filename   = \"best-{epoch:02d}\"\n",
        ")\n",
        "\n",
        "early_stop_cb = EarlyStopping(\n",
        "    monitor  = \"val/total_cost\",\n",
        "    mode     = \"min\",\n",
        "    patience = hparams[\"patience\"],\n",
        "    verbose  = True\n",
        ")\n",
        "\n",
        "lr_monitor_cb = LearningRateMonitor(logging_interval=\"epoch\")\n",
        "\n",
        "# RichProgressBar generates minimal output compared to 'tqdm'\n",
        "progress_bar_cb = RichProgressBar()\n",
        "\n",
        "callbacks = [checkpoint_cb, early_stop_cb, lr_monitor_cb, progress_bar_cb]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "0Fss9jVEVNzN"
      },
      "outputs": [],
      "source": [
        "wandb_logger = WandbLogger(\n",
        "    project     = \"mlpc2025\",\n",
        "    name        = \"1l-projectiontransformer-786 -FINAL VERSION(2)\",\n",
        "    config      = hparams\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zwe0fKdiV5eR",
        "outputId": "26e01934-34ad-4c40-e00b-cf4bf21cb1e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        }
      ],
      "source": [
        "dm = SEDDataModule(\n",
        "    X_train=X_train, Y_train=Y_train, train_files=train_files,\n",
        "    X_val=X_val,     Y_val=Y_val,     val_files=val_files,\n",
        "    X_test=X_test,   Y_test=Y_test,   test_files=test_files,\n",
        "    classes=TARGET_CLASSES,\n",
        "    batch_size=hparams[\"batch_size\"],\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "model = SEDLightningModule(\n",
        "    #input_dim    = hparams[\"input_dim\"],\n",
        "    classes      = TARGET_CLASSES,\n",
        "    #cnn_channels = hparams[\"cnn_channels\"],\n",
        "\n",
        "    dropout      = hparams[\"dropout\"],\n",
        "    lr           = hparams[\"lr\"],\n",
        "    threshold    = hparams[\"threshold\"],\n",
        "    pos_weight   = hparams[\"pos_weight\"]\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    accelerator             = \"gpu\",\n",
        "    devices                 = 1,\n",
        "    max_epochs              = hparams[\"max_epochs\"],\n",
        "    callbacks               = callbacks,\n",
        "    logger                  = wandb_logger,\n",
        "    log_every_n_steps       = 10,\n",
        "    deterministic           = True,\n",
        "    check_val_every_n_epoch = 1,\n",
        "    num_sanity_val_steps    = 0,\n",
        "    precision               = 16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458,
          "referenced_widgets": [
            "88ba73bcde0649d18872dc1ffb1764ff",
            "e5050fc52b6a4a63b751257f6efdd3d2"
          ]
        },
        "id": "GLKkGmzpcC3e",
        "outputId": "84e7108b-fc1b-40a6-f6d8-aac95876389c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory ./mlpc2025/23ib56xo/checkpoints exists and is not empty.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
              "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
              "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
              "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ model     │ Transformer       │ 40.8 M │ train │\n",
              "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ criterion │ BCEWithLogitsLoss │      0 │ train │\n",
              "└───┴───────────┴───────────────────┴────────┴───────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
              "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
              "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ model     │ Transformer       │ 40.8 M │ train │\n",
              "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ criterion │ BCEWithLogitsLoss │      0 │ train │\n",
              "└───┴───────────┴───────────────────┴────────┴───────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mTrainable params\u001b[0m: 40.8 M                                                                                           \n",
              "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
              "\u001b[1mTotal params\u001b[0m: 40.8 M                                                                                               \n",
              "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 163                                                                        \n",
              "\u001b[1mModules in train mode\u001b[0m: 54                                                                                          \n",
              "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 40.8 M                                                                                           \n",
              "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
              "<span style=\"font-weight: bold\">Total params</span>: 40.8 M                                                                                               \n",
              "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 163                                                                        \n",
              "<span style=\"font-weight: bold\">Modules in train mode</span>: 54                                                                                          \n",
              "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88ba73bcde0649d18872dc1ffb1764ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric val/total_cost improved. New best score: 61.784\n",
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric val/total_cost improved by 15.952 >= min_delta = 0.0. New best score: 45.831\n",
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric val/total_cost improved by 5.997 >= min_delta = 0.0. New best score: 39.835\n",
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric val/total_cost improved by 1.002 >= min_delta = 0.0. New best score: 38.833\n",
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric val/total_cost improved by 0.312 >= min_delta = 0.0. New best score: 38.521\n",
            "INFO:pytorch_lightning.callbacks.early_stopping:Metric val/total_cost improved by 1.223 >= min_delta = 0.0. New best score: 37.299\n",
            "INFO:pytorch_lightning.callbacks.early_stopping:Monitored metric val/total_cost did not improve in the last 10 records. Best score: 37.299. Signaling Trainer to stop.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer.fit(model, datamodule=dm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "yGlV4Barkxfg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f5c186af76074b75b4312445989074e4",
            "3e96fc79c4b7497db7811d4d9b6dfb9a"
          ]
        },
        "outputId": "2b5d9ad5-106a-4c03-a3df-85ae5cd24392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Restoring states from the checkpoint path at ./mlpc2025/23ib56xo/checkpoints/best-epoch=05-v1.ckpt\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Loaded model weights from the checkpoint at ./mlpc2025/23ib56xo/checkpoints/best-epoch=05-v1.ckpt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f5c186af76074b75b4312445989074e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1m        Test metric        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       DataLoader 0        \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│\u001b[36m \u001b[0m\u001b[36m    test/Chainsaw_bacc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9258583188056946     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m     test/Chainsaw_f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8014509081840515     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m  test/Chainsaw_precision  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7550359964370728     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m   test/Chainsaw_recall    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8539462685585022     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m    test/Dog Bark_bacc     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9000886082649231     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m     test/Dog Bark_f1      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7239395976066589     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m  test/Dog Bark_precision  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6550871729850769     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m   test/Dog Bark_recall    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8089653253555298     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m    test/Horn Honk_bacc    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8276390433311462     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m     test/Horn Honk_f1     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4182298481464386     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m test/Horn Honk_precision  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.30209922790527344    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m   test/Horn Honk_recall   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6793991327285767     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m   test/Jackhammer_bacc    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6892330646514893     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m    test/Jackhammer_f1     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.41474446654319763    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m test/Jackhammer_precision \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.45351138710975647    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m  test/Jackhammer_recall   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.38208332657814026    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m   test/Lawn Mower_bacc    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7291045784950256     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m    test/Lawn Mower_f1     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5428957939147949     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m test/Lawn Mower_precision \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6624835133552551     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m  test/Lawn Mower_recall   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.4598807990550995     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m   test/Power Drill_bacc   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.766679048538208     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m    test/Power Drill_f1    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3579441010951996     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mtest/Power Drill_precision \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.2654666602611542     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m  test/Power Drill_recall  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5492957830429077     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m  test/Rooster Crow_bacc   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.8767452836036682     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m   test/Rooster Crow_f1    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6566604375839233     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36mtest/Rooster Crow_precision\u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5813953280448914     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m test/Rooster Crow_recall  \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7543103694915771     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m      test/Shout_bacc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7836446166038513     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m       test/Shout_f1       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.42475050687789917    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m   test/Shout_precision    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.3322923183441162     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m     test/Shout_recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5884955525398254     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m      test/Siren_bacc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9261162877082825     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m       test/Siren_f1       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7717857360839844     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m   test/Siren_precision    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6989757418632507     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m     test/Siren_recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     0.861528217792511     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m     test/Speech_bacc      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9201180338859558     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m      test/Speech_f1       \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.7379881143569946     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m   test/Speech_precision   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.6250028014183044     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m    test/Speech_recall     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.9008376002311707     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m    test/cost/Chainsaw     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.2330201864242554     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m    test/cost/Dog Bark     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.2822140455245972     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m    test/cost/Horn Honk    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     7.507616996765137     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m   test/cost/Jackhammer    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     4.156087398529053     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m   test/cost/Lawn Mower    \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    3.0039989948272705     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m   test/cost/Power Drill   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     5.917544841766357     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m  test/cost/Rooster Crow   \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.16979815065860748    \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m      test/cost/Shout      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     6.128602027893066     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m      test/cost/Siren      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     4.022788047790527     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m     test/cost/Speech      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    5.1828107833862305     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m         test/loss         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.5570321083068848     \u001b[0m\u001b[35m \u001b[0m│\n",
              "│\u001b[36m \u001b[0m\u001b[36m      test/total_cost      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m     38.6044807434082      \u001b[0m\u001b[35m \u001b[0m│\n",
              "└─────────────────────────────┴─────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\">         Test metric         </span>┃<span style=\"font-weight: bold\">        DataLoader 0         </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/Chainsaw_bacc      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.9258583188056946      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/Chainsaw_f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.8014509081840515      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">   test/Chainsaw_precision   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.7550359964370728      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/Chainsaw_recall     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.8539462685585022      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/Dog Bark_bacc      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.9000886082649231      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/Dog Bark_f1       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.7239395976066589      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">   test/Dog Bark_precision   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.6550871729850769      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/Dog Bark_recall     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.8089653253555298      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/Horn Honk_bacc     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.8276390433311462      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/Horn Honk_f1      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.4182298481464386      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">  test/Horn Honk_precision   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.30209922790527344     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/Horn Honk_recall    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.6793991327285767      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/Jackhammer_bacc     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.6892330646514893      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/Jackhammer_f1      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.41474446654319763     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">  test/Jackhammer_precision  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.45351138710975647     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">   test/Jackhammer_recall    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.38208332657814026     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/Lawn Mower_bacc     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.7291045784950256      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/Lawn Mower_f1      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.5428957939147949      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">  test/Lawn Mower_precision  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.6624835133552551      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">   test/Lawn Mower_recall    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.4598807990550995      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/Power Drill_bacc    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      0.766679048538208      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/Power Drill_f1     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.3579441010951996      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> test/Power Drill_precision  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.2654666602611542      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">   test/Power Drill_recall   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.5492957830429077      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">   test/Rooster Crow_bacc    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.8767452836036682      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/Rooster Crow_f1     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.6566604375839233      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\"> test/Rooster Crow_precision </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.5813953280448914      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">  test/Rooster Crow_recall   </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.7543103694915771      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/Shout_bacc       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.7836446166038513      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/Shout_f1        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.42475050687789917     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/Shout_precision     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.3322923183441162      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/Shout_recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.5884955525398254      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/Siren_bacc       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.9261162877082825      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">        test/Siren_f1        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.7717857360839844      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/Siren_precision     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.6989757418632507      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/Siren_recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      0.861528217792511      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/Speech_bacc       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.9201180338859558      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/Speech_f1        </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.7379881143569946      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/Speech_precision    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.6250028014183044      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/Speech_recall      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.9008376002311707      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/cost/Chainsaw      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.2330201864242554      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/cost/Dog Bark      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.2822140455245972      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">     test/cost/Horn Honk     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      7.507616996765137      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/cost/Jackhammer     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      4.156087398529053      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/cost/Lawn Mower     </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     3.0039989948272705      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">    test/cost/Power Drill    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      5.917544841766357      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">   test/cost/Rooster Crow    </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.16979815065860748     </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/cost/Shout       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      6.128602027893066      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/cost/Siren       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      4.022788047790527      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">      test/cost/Speech       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     5.1828107833862305      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">          test/loss          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.5570321083068848      </span>│\n",
              "│<span style=\"color: #008080; text-decoration-color: #008080\">       test/total_cost       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">      38.6044807434082       </span>│\n",
              "└─────────────────────────────┴─────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        " test_results = trainer.test(model, datamodule=dm, ckpt_path=\"best\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL PREDICTIONS ON UNSEEN DATASET**"
      ],
      "metadata": {
        "id": "HMP-gY3ILPoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First make sure you have these variables defined (from your training code)\n",
        "classes = TARGET_CLASSES\n",
        "threshold = 0.5  # Your threshold value\n",
        "lr = 1e-5  # Your learning rate\n",
        "\n",
        "# Load the checkpoint with the updated class\n",
        "checkpoint_path = trainer.checkpoint_callback.best_model_path\n",
        "if os.path.exists(checkpoint_path):\n",
        "    model = SEDLightningModule.load_from_checkpoint(\n",
        "        checkpoint_path,\n",
        "        classes=classes,\n",
        "        lr=lr,\n",
        "        threshold=threshold,\n",
        "        pos_weight=torch.tensor(pos_weights)  # Make sure to pass the same pos_weights\n",
        "    )\n",
        "else:\n",
        "    print(\"Checkpoint not found at:\", checkpoint_path)"
      ],
      "metadata": {
        "id": "idZ1t56IDpea"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_dataset(\n",
        "    model: pl.LightningModule,\n",
        "    loader: DataLoader\n",
        ") -> dict[str, dict[str, np.ndarray]]:\n",
        "    \"\"\"\n",
        "    Runs trainer.predict() on `loader` and returns:\n",
        "      preds_by_file[filename][class] = 1D NumPy array of frame‐wise {0,1}.\n",
        "    \"\"\"\n",
        "    trainer = pl.Trainer(accelerator=\"auto\", devices=1)\n",
        "    outputs = trainer.predict(model, dataloaders=loader)\n",
        "\n",
        "    # flatten into lists\n",
        "    all_preds = {c: [] for c in model.classes}\n",
        "    all_files = []\n",
        "    for batch_out in outputs:\n",
        "        for fname, pred in zip(batch_out[\"filenames\"], batch_out[\"preds\"]):\n",
        "            all_files.append(fname)\n",
        "            arr = pred.numpy()  # shape (T_i, C)\n",
        "            for i, cls in enumerate(model.classes):\n",
        "                all_preds[cls].append(arr[:, i])\n",
        "\n",
        "    # repackage into preds_by_file\n",
        "    preds_by_file: dict[str, dict[str, np.ndarray]] = {}\n",
        "    for idx, fname in enumerate(all_files):\n",
        "        preds_by_file.setdefault(fname, {})\n",
        "        for cls in model.classes:\n",
        "            preds_by_file[fname][cls] = all_preds[cls][idx]\n",
        "\n",
        "    return preds_by_file"
      ],
      "metadata": {
        "id": "ofac9RzmJmUn"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def segment_and_save(\n",
        "    preds_by_file: dict[str, dict[str, np.ndarray]],\n",
        "    class_names: list[str],\n",
        "    dataset_path: str,\n",
        "    out_csv: str,\n",
        "    compute_cost: bool = False,\n",
        "    test_files: list[str] = None,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    1) Build segment‐level DataFrame\n",
        "    2) Sanity‐check with check_dataframe()\n",
        "    3) (optional) compute & print cost if val_files is provided\n",
        "    4) save CSV to out_csv\n",
        "    \"\"\"\n",
        "    # 1) aggregate predictions using the function provided in compute_cost.py\n",
        "    pred_df = get_segment_prediction_df(\n",
        "        predictions = preds_by_file,\n",
        "        class_names = class_names\n",
        "    )\n",
        "\n",
        "    # 2) sanity‐check (from compute_cost.py)\n",
        "    check_dataframe(pred_df, dataset_path)\n",
        "\n",
        "    # 3) cost (optional), for sanity check on our custom test split\n",
        "    if compute_cost and test_files is not None:\n",
        "        gt_df = get_ground_truth_df(test_files, dataset_path) # from compute_cost.py\n",
        "        total, breakdown = total_cost(pred_df, gt_df) # from compute_cost.py\n",
        "        print(f\"\\nTotal cost: {total:.4f}\")\n",
        "\n",
        "        gt_csv = os.path.splitext(out_csv)[0] + \"_ground_truth.csv\"\n",
        "        gt_df.to_csv(gt_csv, index=False)\n",
        "        print(f\"Saved ground truth segments to {gt_csv}\")\n",
        "\n",
        "    # 4) save\n",
        "    pred_df.to_csv(out_csv, index=False)\n",
        "    print(f\"Saved segment predictions to {out_csv}\")\n",
        "\n",
        "    return pred_df"
      ],
      "metadata": {
        "id": "wPVTSGjCJ-w8"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) CUSTOMER SET (no labels → compute_cost=False)\n",
        "customer_files = CUSTOMER_METADATA[\"filename\"].unique()\n",
        "X_cust, _ = read_files(customer_files, TARGET_CLASSES,\n",
        "                       features_dir=CUSTOMER_AUDIO_FEATURES_DIR,\n",
        "                       labels_dir=None)\n",
        "cust_dataset = SequenceDataset(X_cust, None, TARGET_CLASSES, customer_files)\n",
        "cust_loader  = DataLoader(cust_dataset, batch_size=8, collate_fn=collate_fn)\n",
        "\n",
        "cust_preds = predict_dataset(model, cust_loader)\n",
        "segment_and_save(\n",
        "    preds_by_file = cust_preds,\n",
        "    class_names   = TARGET_CLASSES,\n",
        "    dataset_path  = CUSTOMER_DATASET_PATH,\n",
        "    out_csv       = \"customer_predictions.csv\",\n",
        "    compute_cost  = False,  # can't compute on customer's secret test set\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615,
          "referenced_widgets": [
            "14dad7bd651e4e1dbe30312fa92ee697",
            "4a1abadfe6b24bb9a170a233fe4b1c9e",
            "fbc759dbc31e421f913b08266fdbbdc9",
            "d5244cead7b04b678be26fceafe761a6",
            "95f58375acaf4bd0b2a557e3baa8faf5",
            "037452436c8d4b2eb70d870bb570a943",
            "3712582c5b9d4b2a8da58b485dbb16c6",
            "3def9f1c7ae64e12a7ce82991abb747c",
            "b5b3eaeb53744b4fb8b3976b7571483d",
            "7afe02fdb4b7425fb3643bb4548270a6",
            "f714cb0769934a088d1591007a437a58"
          ]
        },
        "id": "4BGB6VfceO6A",
        "outputId": "202cef5c-68bc-4b4d-c19b-9ebf5cd517e5"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.11/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Predicting: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14dad7bd651e4e1dbe30312fa92ee697"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved segment predictions to customer_predictions.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         filename  onset  Speech  Shout  Chainsaw  Jackhammer  Lawn Mower  \\\n",
              "0      386984.mp3    0.0       1      1         0           0           0   \n",
              "1      386984.mp3    1.2       1      1         0           0           0   \n",
              "2      386984.mp3    2.4       1      1         0           0           0   \n",
              "3      386984.mp3    3.6       1      1         0           0           0   \n",
              "4      386984.mp3    4.8       1      1         0           0           0   \n",
              "...           ...    ...     ...    ...       ...         ...         ...   \n",
              "52186  507531.mp3   21.6       0      0         0           0           0   \n",
              "52187  507531.mp3   22.8       0      0         0           0           0   \n",
              "52188  507531.mp3   24.0       0      0         0           0           0   \n",
              "52189  507531.mp3   25.2       0      0         0           0           0   \n",
              "52190  507531.mp3   26.4       0      0         0           0           0   \n",
              "\n",
              "       Power Drill  Dog Bark  Rooster Crow  Horn Honk  Siren  \n",
              "0                0         0             0          0      0  \n",
              "1                0         0             0          0      0  \n",
              "2                0         0             0          0      0  \n",
              "3                0         0             0          0      0  \n",
              "4                0         0             0          0      0  \n",
              "...            ...       ...           ...        ...    ...  \n",
              "52186            0         0             0          0      0  \n",
              "52187            0         0             0          0      0  \n",
              "52188            0         0             0          0      0  \n",
              "52189            0         0             0          0      0  \n",
              "52190            0         0             0          0      0  \n",
              "\n",
              "[52191 rows x 12 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eebf2cbb-3755-4506-bc07-8b3fa1c50f86\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>onset</th>\n",
              "      <th>Speech</th>\n",
              "      <th>Shout</th>\n",
              "      <th>Chainsaw</th>\n",
              "      <th>Jackhammer</th>\n",
              "      <th>Lawn Mower</th>\n",
              "      <th>Power Drill</th>\n",
              "      <th>Dog Bark</th>\n",
              "      <th>Rooster Crow</th>\n",
              "      <th>Horn Honk</th>\n",
              "      <th>Siren</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>386984.mp3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>386984.mp3</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>386984.mp3</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>386984.mp3</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>386984.mp3</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52186</th>\n",
              "      <td>507531.mp3</td>\n",
              "      <td>21.6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52187</th>\n",
              "      <td>507531.mp3</td>\n",
              "      <td>22.8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52188</th>\n",
              "      <td>507531.mp3</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52189</th>\n",
              "      <td>507531.mp3</td>\n",
              "      <td>25.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52190</th>\n",
              "      <td>507531.mp3</td>\n",
              "      <td>26.4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52191 rows × 12 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eebf2cbb-3755-4506-bc07-8b3fa1c50f86')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-eebf2cbb-3755-4506-bc07-8b3fa1c50f86 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-eebf2cbb-3755-4506-bc07-8b3fa1c50f86');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-e5c93256-4d7c-48ab-8e74-a1fa5e9d1b63\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e5c93256-4d7c-48ab-8e74-a1fa5e9d1b63')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-e5c93256-4d7c-48ab-8e74-a1fa5e9d1b63 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \")\",\n  \"rows\": 52191,\n  \"fields\": [\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2742,\n        \"samples\": [\n          \"193778.mp3\",\n          \"232974.mp3\",\n          \"362939.mp3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"onset\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.247338722702892,\n        \"min\": 0.0,\n        \"max\": 28.8,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          9.6,\n          19.2,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Speech\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Shout\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chainsaw\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Jackhammer\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lawn Mower\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Power Drill\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Dog Bark\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rooster Crow\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Horn Honk\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Siren\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "88ba73bcde0649d18872dc1ffb1764ff": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_e5050fc52b6a4a63b751257f6efdd3d2",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Epoch 15/99 \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 155/155 \u001b[2m0:00:30 • 0:00:00\u001b[0m \u001b[2;4m5.14it/s\u001b[0m \u001b[3mv_num: 56xo train/loss_step: 0.992\u001b[0m\n                                                                                 \u001b[3mval/loss: 0.503 val/total_cost:   \u001b[0m\n                                                                                 \u001b[3m40.763 train/loss_epoch: 0.502    \u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 15/99 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 155/155 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:30 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">5.14it/s</span> <span style=\"font-style: italic\">v_num: 56xo train/loss_step: 0.992</span>\n                                                                                 <span style=\"font-style: italic\">val/loss: 0.503 val/total_cost:   </span>\n                                                                                 <span style=\"font-style: italic\">40.763 train/loss_epoch: 0.502    </span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "e5050fc52b6a4a63b751257f6efdd3d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5c186af76074b75b4312445989074e4": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_3e96fc79c4b7497db7811d4d9b6dfb9a",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "Testing \u001b[38;2;98;6;224m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m 52/52 \u001b[2m0:00:04 • 0:00:00\u001b[0m \u001b[2;4m12.21it/s\u001b[0m  \n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Testing <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> 52/52 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:00:04 • 0:00:00</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">12.21it/s</span>  \n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "3e96fc79c4b7497db7811d4d9b6dfb9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14dad7bd651e4e1dbe30312fa92ee697": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a1abadfe6b24bb9a170a233fe4b1c9e",
              "IPY_MODEL_fbc759dbc31e421f913b08266fdbbdc9",
              "IPY_MODEL_d5244cead7b04b678be26fceafe761a6"
            ],
            "layout": "IPY_MODEL_95f58375acaf4bd0b2a557e3baa8faf5"
          }
        },
        "4a1abadfe6b24bb9a170a233fe4b1c9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_037452436c8d4b2eb70d870bb570a943",
            "placeholder": "​",
            "style": "IPY_MODEL_3712582c5b9d4b2a8da58b485dbb16c6",
            "value": "Predicting DataLoader 0: 100%"
          }
        },
        "fbc759dbc31e421f913b08266fdbbdc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3def9f1c7ae64e12a7ce82991abb747c",
            "max": 343,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b5b3eaeb53744b4fb8b3976b7571483d",
            "value": 343
          }
        },
        "d5244cead7b04b678be26fceafe761a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7afe02fdb4b7425fb3643bb4548270a6",
            "placeholder": "​",
            "style": "IPY_MODEL_f714cb0769934a088d1591007a437a58",
            "value": " 343/343 [00:16&lt;00:00, 20.98it/s]"
          }
        },
        "95f58375acaf4bd0b2a557e3baa8faf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "037452436c8d4b2eb70d870bb570a943": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3712582c5b9d4b2a8da58b485dbb16c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3def9f1c7ae64e12a7ce82991abb747c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5b3eaeb53744b4fb8b3976b7571483d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7afe02fdb4b7425fb3643bb4548270a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f714cb0769934a088d1591007a437a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}