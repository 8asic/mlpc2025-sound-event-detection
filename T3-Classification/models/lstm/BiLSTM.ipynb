{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04be28a9-9ba4-4416-a956-55ee0cbaafd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc686267-9625-4602-af65-2d7c40428cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Airplane', 'Alarm', 'Beep/Bleep', 'Bell', 'Bicycle', 'Bird Chirp', 'Bus', 'Car', 'Cat Meow',\n",
    "        'Chainsaw', 'Clapping', 'Cough', 'Cow Moo', 'Cowbell', 'Crying', 'Dog Bark', 'Doorbell', 'Drip',\n",
    "        'Drums', 'Fire', 'Footsteps', 'Guitar', 'Hammer', 'Helicopter', 'Hiccup', 'Horn Honk', 'Horse Neigh',\n",
    "        'Insect Buzz', 'Jackhammer', 'Laughter', 'Lawn Mower', 'Motorcycle', 'Piano', 'Pig Oink', 'Power Drill',\n",
    "        'Power Saw', 'Rain', 'Rooster Crow', 'Saxophone', 'Sewing Machine', 'Sheep/Goat Bleat', 'Ship/Boat',\n",
    "        'Shout', 'Singing', 'Siren', 'Sneeze', 'Snoring', 'Speech', 'Stream/River', 'Thunder', 'Train', 'Truck',\n",
    "        'Trumpet', 'Vacuum Cleaner', 'Violin', 'Washing Machine', 'Waves', 'Wind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71404b38-00ba-49a2-8a4e-a95c9ffa2da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27552, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann_df = pd.read_csv(\n",
    "    'annotations.csv'\n",
    ")\n",
    "meta_df = pd.read_csv(\n",
    "    'metadata.csv'\n",
    ")\n",
    "ann_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f11e6d1-1452-4a99-bd44-2fc938101e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = meta_df.sample(len(meta_df),random_state=42)['filename'].unique()[:int(len(meta_df)*0.7)]\n",
    "validation_filename = meta_df.sample(len(meta_df),random_state=42)['filename'].unique()[int(len(meta_df)*0.7):int(len(meta_df)*0.9)]\n",
    "test_filename = meta_df.sample(len(meta_df),random_state=42)['filename'].unique()[int(len(meta_df)*0.9):len(meta_df)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc57b422-7add-4e26-ac51-9a123813dc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_labels(file_labels):\n",
    "    __y = []\n",
    "    for frame_labels in file_labels:\n",
    "        if(sum(frame_labels) == 0):\n",
    "            __y.append([0])\n",
    "        elif(np.count_nonzero(frame_labels) == len(frame_labels)):\n",
    "             __y.append([1])\n",
    "        else: #The annotators don't agree on the label\n",
    "            __y.append([np.random.choice(frame_labels)])\n",
    "    return __y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee075e36-ef11-4985-ada6-54b5c6773d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dir = \"audio_features\"\n",
    "labels_dir = \"labels\"\n",
    "\n",
    "import itertools\n",
    "def read_files(file_names):\n",
    "    X_train = []\n",
    "    Y_train = {c: [] for c in categories}  # Initialize label dictionary\n",
    "    \n",
    "    for f in file_names:\n",
    "        # Load melspectrogram and MFCC features\n",
    "        features_mel = np.load(os.path.join(features_dir, f.split('.')[0] + '.npz'))[\"melspectrogram\"]\n",
    "        features_mfcc = np.load(os.path.join(features_dir, f.split('.')[0] + '.npz'))[\"mfcc\"]\n",
    "        \n",
    "        \n",
    "        # Pad or truncate all features to have the same number of timesteps\n",
    "        min_length = min(features_mel.shape[0], features_mfcc.shape[0])\n",
    "        features_mel = features_mel[:min_length]\n",
    "        features_mfcc = features_mfcc[:min_length]\n",
    "        \n",
    "        # Concatenate features along feature axis (axis=1)\n",
    "        features = np.concatenate([features_mel, features_mfcc], axis=1)\n",
    "        X_train.append(features)\n",
    "        \n",
    "        # Load and process labels\n",
    "        y = np.load(os.path.join(labels_dir, f.split('.')[0] + '_labels.npz'))\n",
    "        for c in categories:\n",
    "            _y = aggregate_labels(y[c])\n",
    "            Y_train[c].extend(list(itertools.chain.from_iterable(_y))[:min_length])  # Match length\n",
    "    \n",
    "    X_train = np.concatenate(X_train)\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54c1c631-32da-416f-b615-55964230d722",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def preprocessing(array):\n",
    "    s=StandardScaler()\n",
    "    scaled_array = s.fit_transform(array)\n",
    "    scalar =s.fit(array)\n",
    "    return scaled_array,scalar.mean_,scalar.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b21a081e-db45-47c6-b52c-41483804a995",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y = read_files(train_filename)\n",
    "val_x, val_y = read_files(validation_filename)\n",
    "test_x, test_y = read_files(test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fb0ce06-3400-4f09-938d-c7a127677dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train_x,mu,std =preprocessing(train_x)\n",
    "scaled_validation_x = (val_x - mu)/std\n",
    "scaled_test_x = (test_x - mu)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b233814b-7e49-465b-98f0-d1f79f479746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1078243, 58)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = np.array([train_y[cls] for cls in categories]).T\n",
    "val_y = np.array([val_y[cls] for cls in categories]).T\n",
    "test_y = np.array([test_y[cls] for cls in categories]).T\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c9ef432-24b1-4961-b1d4-b0c239e7d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BiLSTMAED(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes, num_layers=2, dropout=0.3):\n",
    "        super(BiLSTMAED, self).__init__()\n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.bilstm(x)  \n",
    "        out = self.classifier(lstm_out)  \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37c3aed8-d042-4d0d-a8e6-43e0f749e162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTMAED(\n",
      "  (bilstm): LSTM(96, 128, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=58, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch 1/4 | Train Loss: 0.0781 | Train Accuracy: 97.96% | Val Loss: 0.0781 | Val Accuracy: 97.96%\n",
      "Epoch 2/4 | Train Loss: 0.0704 | Train Accuracy: 98.01% | Val Loss: 0.0778 | Val Accuracy: 97.97%\n",
      "Epoch 3/4 | Train Loss: 0.0677 | Train Accuracy: 98.05% | Val Loss: 0.0779 | Val Accuracy: 97.96%\n",
      "Epoch 4/4 | Train Loss: 0.0661 | Train Accuracy: 98.07% | Val Loss: 0.0784 | Val Accuracy: 97.97%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "model = BiLSTMAED(input_dim=96, hidden_dim=128, num_classes=58).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "print(model)\n",
    "\n",
    "scaled_train_x = torch.tensor(scaled_train_x, dtype=torch.float32)\n",
    "train_y = torch.tensor(train_y, dtype=torch.float32)\n",
    "val_x = torch.tensor(val_x, dtype=torch.float32)\n",
    "val_y = torch.tensor(val_y, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Datasets\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(scaled_train_x, train_y)\n",
    "val_dataset = TensorDataset(val_x, val_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 4\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device).float()\n",
    "        y_batch = y_batch.to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_batch)  # (B, T, C)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Train accuracy calculation\n",
    "        train_predictions = (output > 0.5).int()\n",
    "        train_correct += (train_predictions == y_batch.int()).sum().item()\n",
    "        train_total += y_batch.numel()\n",
    "\n",
    "    train_accuracy = train_correct / train_total\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            x_val = x_val.to(device).float()\n",
    "            y_val = y_val.to(device).float()\n",
    "\n",
    "            val_output = model(x_val)\n",
    "            val_loss += criterion(val_output, y_val).item()\n",
    "            \n",
    "            # Validation accuracy calculation\n",
    "            val_predictions = (val_output > 0.5).int()\n",
    "            val_correct += (val_predictions == y_val.int()).sum().item()\n",
    "            val_total += y_val.numel()\n",
    "\n",
    "    val_accuracy = val_correct / val_total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "          f\"Train Accuracy: {train_accuracy * 100:.2f}% | \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f} | \"\n",
    "          f\"Val Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "torch.save(model.state_dict(), \"BiLSTM.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88e473ae-6c27-4a51-bbf1-be622be34220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0811 | Test Accuracy: 97.93%\n"
     ]
    }
   ],
   "source": [
    "# Test set evaluation\n",
    "test_x = torch.tensor(test_x, dtype=torch.float32)\n",
    "test_y = torch.tensor(test_y, dtype=torch.float32)\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in test_loader:\n",
    "        x_test = x_test.to(device).float()\n",
    "        y_test = y_test.to(device).float()\n",
    "\n",
    "        test_output = model(x_test)\n",
    "        test_loss += criterion(test_output, y_test).item()\n",
    "        \n",
    "        # Test accuracy calculation\n",
    "        test_predictions = (test_output > 0.5).int()\n",
    "        test_correct += (test_predictions == y_test.int()).sum().item()\n",
    "        test_total += y_test.numel()\n",
    "\n",
    "test_accuracy = test_correct / test_total\n",
    "print(f\"Test Loss: {test_loss/len(test_loader):.4f} | \"\n",
    "      f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ddada22-4bd2-4778-aba3-03b427e49a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\beiba\\AppData\\Local\\Temp\\ipykernel_18252\\478012964.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_x = torch.tensor(test_x, dtype=torch.float32)\n",
      "C:\\Users\\beiba\\AppData\\Local\\Temp\\ipykernel_18252\\478012964.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_y = torch.tensor(test_y, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Test set evaluation\n",
    "test_x = torch.tensor(test_x, dtype=torch.float32)\n",
    "test_y = torch.tensor(test_y, dtype=torch.float32)\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "model.eval()\n",
    "all_test_labels = []\n",
    "all_test_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in test_loader:\n",
    "        x_test = x_test.to(device).float()\n",
    "        y_test = y_test.to(device).float()\n",
    "\n",
    "        test_output = model(x_test)\n",
    "        test_predictions = (test_output > 0.5).int().cpu().numpy()  # Convert to binary predictions\n",
    "        \n",
    "        all_test_labels.extend(y_test.cpu().numpy())     # Store true labels\n",
    "        all_test_predictions.extend(test_predictions)    # Store predicted labels\n",
    "\n",
    "# Convert lists to numpy arrays for further calculations\n",
    "import numpy as np\n",
    "all_test_labels = np.array(all_test_labels)\n",
    "all_test_predictions = np.array(all_test_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "245492d6-395e-4d25-bbca-fbfebf6136cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:          0.9794\n",
      "Precision:         0.6515\n",
      "Recall:            0.0741\n",
      "F1 Score:          0.1331\n",
      "average_balanced_accuracy:          0.5366\n"
     ]
    }
   ],
   "source": [
    "# Flatten the arrays for calculation\n",
    "labels_flat = all_test_labels.flatten()\n",
    "preds_flat = all_test_predictions.flatten()\n",
    "\n",
    "# Calculate TP, FP, FN, TN\n",
    "TP = np.sum((labels_flat == 1) & (preds_flat == 1))\n",
    "FP = np.sum((labels_flat == 0) & (preds_flat == 1))\n",
    "FN = np.sum((labels_flat == 1) & (preds_flat == 0))\n",
    "TN = np.sum((labels_flat == 0) & (preds_flat == 0))\n",
    "\n",
    "# Accuracy Calculation\n",
    "accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "\n",
    "# Precision Calculation\n",
    "precision = TP / (TP + FP) if (TP + FP) > 0 else 0.0\n",
    "\n",
    "# Recall Calculation\n",
    "recall = TP / (TP + FN) if (TP + FN) > 0 else 0.0\n",
    "\n",
    "sensitivity = TP / (TP + FN)\n",
    "specificity = TN / (TN + FP)\n",
    "balanced_accuracy = (sensitivity + specificity) / 2\n",
    "average_balanced_accuracy = balanced_accuracy.mean()\n",
    "\n",
    "# F1-Score Calculation\n",
    "f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "print(f\"Accuracy:          {accuracy:.4f}\")\n",
    "print(f\"Precision:         {precision:.4f}\")\n",
    "print(f\"Recall:            {recall:.4f}\")\n",
    "print(f\"F1 Score:          {f1_score:.4f}\")\n",
    "print(f\"average_balanced_accuracy:          {average_balanced_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
