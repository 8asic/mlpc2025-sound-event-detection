{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "350e1503-88c0-4c28-ba34-4fd186ae7975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ecebede-352b-473a-8b89-fc2021bc2438",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['Airplane', 'Alarm', 'Beep/Bleep', 'Bell', 'Bicycle', 'Bird Chirp', 'Bus', 'Car', 'Cat Meow',\n",
    "        'Chainsaw', 'Clapping', 'Cough', 'Cow Moo', 'Cowbell', 'Crying', 'Dog Bark', 'Doorbell', 'Drip',\n",
    "        'Drums', 'Fire', 'Footsteps', 'Guitar', 'Hammer', 'Helicopter', 'Hiccup', 'Horn Honk', 'Horse Neigh',\n",
    "        'Insect Buzz', 'Jackhammer', 'Laughter', 'Lawn Mower', 'Motorcycle', 'Piano', 'Pig Oink', 'Power Drill',\n",
    "        'Power Saw', 'Rain', 'Rooster Crow', 'Saxophone', 'Sewing Machine', 'Sheep/Goat Bleat', 'Ship/Boat',\n",
    "        'Shout', 'Singing', 'Siren', 'Sneeze', 'Snoring', 'Speech', 'Stream/River', 'Thunder', 'Train', 'Truck',\n",
    "        'Trumpet', 'Vacuum Cleaner', 'Violin', 'Washing Machine', 'Waves', 'Wind']\n",
    "\n",
    "features_dir = r\"C:\\Users\\abdul\\Desktop\\Uni\\ML Pattern Classification\\Project\\Classification\\MLPC2025_classification\\audio_features\"\n",
    "labels_dir = r\"C:\\Users\\abdul\\Desktop\\Uni\\ML Pattern Classification\\Project\\Classification\\MLPC2025_classification\\labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7df7183-b6ac-4161-b9dc-02e828a41c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_df = pd.read_csv( 'annotations.csv')\n",
    "meta_df = pd.read_csv('metadata.csv')\n",
    "\n",
    "\n",
    "train_filename = meta_df.sample(len(meta_df),random_state=42)['filename'].unique()[:int(len(meta_df)*0.7)]\n",
    "validation_filename = meta_df.sample(len(meta_df),random_state=42)['filename'].unique()[int(len(meta_df)*0.7):int(len(meta_df)*0.9)]\n",
    "test_filename = meta_df.sample(len(meta_df),random_state=42)['filename'].unique()[int(len(meta_df)*0.9):len(meta_df)]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d09b0772-e9c5-4552-a48f-d611a394a660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_labels(file_labels):\n",
    "    __y = []\n",
    "    for frame_labels in file_labels:\n",
    "        if(sum(frame_labels) == 0):\n",
    "            __y.append([0])\n",
    "        elif(np.count_nonzero(frame_labels) == len(frame_labels)):\n",
    "             __y.append([1])\n",
    "        else: #The annotators don't agree on the label\n",
    "            __y.append([np.random.choice(frame_labels)])\n",
    "    return __y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2f0b94c-ec07-44e7-bb25-db759dce3c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def read_files(file_names):\n",
    "    X_train = []\n",
    "    Y_train = {}\n",
    "    for c in categories:\n",
    "        Y_train[c] = []\n",
    "    for f in file_names: #we are not loading the entire dataset due to processing time\n",
    "        features = np.load(os.path.join(features_dir , f.split('.')[0] + '.npz'))[\"melspectrogram\"]\n",
    "        X_train.append(features)\n",
    "        y = np.load(os.path.join(labels_dir , f.split('.')[0] + '_labels.npz'))\n",
    "        for c in categories:\n",
    "            _y = aggregate_labels(y[c])\n",
    "            Y_train[c].extend(list(itertools.chain.from_iterable(_y)))\n",
    "    X_train = np.concatenate(X_train)\n",
    "    return X_train, Y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcbeec8a-f555-4f25-8366-c4718d085860",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,train_y = read_files(train_filename)\n",
    "val_x, val_y = read_files(validation_filename)\n",
    "test_x, test_y = read_files(test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04e6c655-ea47-45a0-9c28-aa320059acf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of train set:(1078243, 64), shape of val set:(305277, 64), shape of test set:(155057, 64)\n"
     ]
    }
   ],
   "source": [
    "train_x.shape\n",
    "val_x.shape\n",
    "test_x.shape\n",
    "print(f'shape of train set:{train_x.shape}, shape of val set:{val_x.shape}, shape of test set:{test_x.shape}')\n",
    "#print(f'shape of train_y set:{train_y.shape}, shape of val_y set:{val_y.shape}, shape of test_y set:{test_y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83db4ede-3c45-4bc0-bc34-d3db1b99a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def log_scalling(array):\n",
    "    epsilon = 1e-10  \n",
    "    log_array = np.log(array + epsilon)\n",
    "    return log_array\n",
    "    \n",
    "def z_score(array):\n",
    "    s = StandardScaler()\n",
    "    scaled_array = s.fit_transform(array)\n",
    "    return scaled_array,s.mean_,s.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1336578-23fd-4404-b317-3f91ee519cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train_x,log_validation_x,log_test_x = log_scalling(train_x),log_scalling(val_x),log_scalling(test_x)\n",
    "\n",
    "\n",
    "scaled_train_x,mu,std = z_score(log_train_x)\n",
    "scaled_validation_x = (log_validation_x - mu)/std\n",
    "scaled_test_x = (log_test_x - mu)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aa9405e-bde9-4833-9af0-4f11d50532bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1078243, 58)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = np.array([train_y[cls] for cls in categories]).T\n",
    "val_y = np.array([val_y[cls] for cls in categories]).T\n",
    "test_y = np.array([test_y[cls] for cls in categories]).T\n",
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff8dfbda-877b-4b41-af13-e58092168a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrogramTransformer(nn.Module):\n",
    "    def __init__(self,mel_bin=64,em_dim=128,num_labels=58 , n_head=4 , num_layer=2,dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.input_projection = nn.Linear(mel_bin,em_dim)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=em_dim,nhead=n_head,dropout=dropout,batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer,num_layer)\n",
    "        self.classifier = nn.Linear(em_dim,num_labels)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.input_projection(x)\n",
    "        x = self.transformer(x)\n",
    "        logits = self.classifier(x)\n",
    "        return logits  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20779763-ef12-4b6b-b59a-f46e86a23204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b049c44-9551-4b4d-9819-0ff53b0dc397",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_4976\\744980643.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scaled_train_x = torch.tensor(scaled_train_x, dtype=torch.float32)\n",
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_4976\\744980643.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_y = torch.tensor(train_y, dtype=torch.float32)\n",
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_4976\\744980643.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scaled_validation_x = torch.tensor(scaled_validation_x, dtype=torch.float32)\n",
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_4976\\744980643.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_y = torch.tensor(val_y, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4 | Train Loss: 0.0724 | Train Acc: 98.01% | Val Loss: 0.0805 | Val Acc: 97.90%\n",
      "Epoch 2/4 | Train Loss: 0.0639 | Train Acc: 98.13% | Val Loss: 0.0823 | Val Acc: 97.85%\n",
      "Epoch 3/4 | Train Loss: 0.0605 | Train Acc: 98.20% | Val Loss: 0.0825 | Val Acc: 97.86%\n",
      "Epoch 4/4 | Train Loss: 0.0584 | Train Acc: 98.24% | Val Loss: 0.0829 | Val Acc: 97.82%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "model = SpectrogramTransformer().to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Datasets\n",
    "batch_size = 32\n",
    "scaled_train_x = torch.tensor(scaled_train_x, dtype=torch.float32)\n",
    "train_y = torch.tensor(train_y, dtype=torch.float32)\n",
    "scaled_validation_x = torch.tensor(scaled_validation_x, dtype=torch.float32)\n",
    "val_y = torch.tensor(val_y, dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(scaled_train_x, train_y)\n",
    "val_dataset = TensorDataset(scaled_validation_x, val_y)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 4\n",
    "from torch.nn.functional import sigmoid\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch = x_batch.to(device).float()\n",
    "        y_batch = y_batch.to(device).float()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_batch)  # raw logits\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Accuracy: apply sigmoid and threshold\n",
    "        preds = (sigmoid(output) > 0.5).int()\n",
    "        targets = y_batch.int()\n",
    "        train_correct += (preds == targets).sum().item()\n",
    "        train_total += targets.numel()\n",
    "\n",
    "    train_accuracy = train_correct / train_total\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x_val, y_val in val_loader:\n",
    "            x_val = x_val.to(device).float()\n",
    "            y_val = y_val.to(device).float()\n",
    "\n",
    "            val_output = model(x_val)\n",
    "            val_loss += criterion(val_output, y_val).item()\n",
    "\n",
    "            preds = (sigmoid(val_output) > 0.5).int()\n",
    "            targets = y_val.int()\n",
    "            val_correct += (preds == targets).sum().item()\n",
    "            val_total += targets.numel()\n",
    "\n",
    "    val_accuracy = val_correct / val_total\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train Loss: {train_loss/len(train_loader):.4f} | \"\n",
    "          f\"Train Acc: {train_accuracy*100:.2f}% | \"\n",
    "          f\"Val Loss: {val_loss/len(val_loader):.4f} | \"\n",
    "          f\"Val Acc: {val_accuracy*100:.2f}%\")\n",
    "\n",
    "torch.save(model.state_dict(), 'spectrogram_transformer_weights.pth')\n",
    "torch.save(model, 'spectrogram_transformer_full_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9151b45d-b9f6-48fb-9f36-143187753051",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_4976\\1777780699.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scaled_test_x = torch.tensor(scaled_test_x, dtype=torch.float32)\n",
      "C:\\Users\\abdul\\AppData\\Local\\Temp\\ipykernel_4976\\1777780699.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_y = torch.tensor(test_y, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.81%\n"
     ]
    }
   ],
   "source": [
    "scaled_test_x = torch.tensor(scaled_test_x, dtype=torch.float32)\n",
    "test_y = torch.tensor(test_y, dtype=torch.float32)\n",
    "\n",
    "test_dataset = TensorDataset(scaled_test_x, test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_test, y_test in test_loader:\n",
    "        x_test = x_test.to(device).float()\n",
    "        y_test = y_test.to(device).float()\n",
    "\n",
    "        output = model(x_test)\n",
    "        preds = (sigmoid(output) > 0.5).int()\n",
    "        targets = y_test.int()\n",
    "\n",
    "        test_correct += (preds == targets).sum().item()\n",
    "        test_total += targets.numel()\n",
    "\n",
    "test_accuracy = test_correct / test_total\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4420b1dd-60aa-4848-9713-2e949a398bca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
